{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace approximation & free-energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### § Free-energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fristonian free-energy is\n",
    "\n",
    "$$\n",
    "F = U - S\n",
    "$$\n",
    "\n",
    "which comprises an energy term\n",
    "\n",
    "$$\n",
    "U = \\left\\langle \\ln p(y, \\vartheta|m) \\right\\rangle_q = \\left\\langle L \\right\\rangle_q\n",
    "$$\n",
    "\n",
    "and a (negative) Shannon entropy term\n",
    "\n",
    "$$\n",
    "S = \\left\\langle \\ln q(\\vartheta)\\right\\rangle\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### § Mean-field approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With mean-field approximation over the variational density, $q$\n",
    "\n",
    "$$\n",
    "q(\\vartheta) = \\prod_i q_i(\\vartheta_i) = \\prod_i q_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us for now assume the following case\n",
    "\n",
    "$$\n",
    "q(\\vartheta) = q_i(\\vartheta_i) q_j(\\vartheta_j) = q_i q_j,\\;\\;\\; j = \\backslash i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and note that the following satisfies $\\delta F / \\delta q = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "    \\ln q_i &= \\ln Z_i + V(\\vartheta_i) = \\ln Z_i + \\left\\langle L(\\vartheta)\\right\\rangle_{q_j}\\\\\n",
    "    \\end{align}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $V_i=V(\\vartheta_i)$ is known as the _variational energy_ and speask to the joint probability of data and parameters, $L$, expected under its Markov blanket, $q_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under Laplace assumption, let us suppose that\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    q_i &\\sim N(\\vartheta_i| \\mu_i, \\Sigma_i)\\\\\n",
    "    \\end{align}\n",
    "$$\n",
    "\n",
    "are Gaussian, where\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\Sigma_i &= \\left\\langle (\\vartheta_i - \\mu_i)(\\vartheta_i - \\mu_i)^T\\right\\rangle\n",
    "    \\end{align}\n",
    "$$\n",
    "\n",
    "is the covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### § Taylor expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the factorisation, we write\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    F &= U - S\\\\\n",
    "    U &= \\left\\langle L(\\vartheta)\\right\\rangle_{q_i q_j}\\\\\n",
    "    S &= \\left\\langle\\ln q_i\\right\\rangle_{q_i} + \\left\\langle\\ln q_j\\right\\rangle_{q_j}\n",
    "    \\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The (neg-)entropies are (see note [A.1](#A.1))\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    S &= -\\frac{D_i}{2}(1 + \\ln 2\\pi) - \n",
    "        \\frac 1 2\\ln|\\Sigma_i| - \\frac{D_j}{2}(1 + \\ln 2\\pi) -\\frac 1 2 \\ln|\\Sigma_j|\\\\\n",
    "    &= -\\frac{D_i}{2}\\ln 2\\pi e -\\frac 1 2\\ln|\\Sigma_i| - \\frac{D_j}{2}\\ln 2\\pi e -\\frac 1 2\\ln|\\Sigma_j|\n",
    "    \\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, with second-order truncation (dropping bilinear terms)\n",
    "\n",
    "$$\n",
    "L(\\vartheta) \\approx L(\\mu) + (\\vartheta_i - \\mu_i)L^{(\\vartheta_i)}(\\mu_i, \\mu_j) + \n",
    "    (\\vartheta_j - \\mu_j)L^{(\\vartheta_j)}(\\mu_i, \\mu_j)\n",
    "    +\\frac 1 2\\left[\n",
    "    (\\vartheta_i - \\mu_i)^2L^{(\\vartheta_i\\vartheta_i)}(\\mu_i, \\mu_j) + \n",
    "    (\\vartheta_j - \\mu_j)^2 L^{(\\vartheta_j\\vartheta_j)}(\\mu_i, \\mu_j)\\right],\n",
    "$$\n",
    "\n",
    "where $L^{(\\vartheta_i\\vartheta_i)}$ denotes $\\partial^2 L/\\partial \\vartheta_i^2$ evaluated at its mode $\\mu$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and write\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    U &= L(\\mu) + \\left(\\langle\\vartheta_i\\rangle-\\mu_i\\right)L^{(\\vartheta_i)} +\n",
    "        \\left(\\langle\\vartheta_j-\\mu_j\\rangle\\right)L^{(\\vartheta_j)}\n",
    "        + \\frac 1 2 \\left[\\langle (\\vartheta_i - \\mu_i)^2\\rangle L^{(\\vartheta_i \\vartheta_i)} +\n",
    "        \\langle (\\vartheta_j - \\mu_j)^2\\rangle\n",
    "        L_{(\\vartheta_j \\vartheta_j)}\\right]\\\\\n",
    "    &= L(\\mu) + \\frac 1 2 \\left[\\Sigma_i L^{(\\vartheta_i \\vartheta_i)} + \\Sigma_j L^{(\\vartheta_j \\vartheta_j)}\\right]\n",
    "    \\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the free-energy becomes\n",
    "\n",
    "$$\n",
    "F = L(\\mu) + \\frac 1 2[\\Sigma_i L^{(\\vartheta_i \\vartheta_i)} + \\Sigma_j L^{(\\vartheta_j \\vartheta_j)}] +\\frac{D_i}{2}\\ln 2\\pi e +\\frac 1 2\\ln|\\Sigma_i| + \\frac{D_j}{2}\\ln 2\\pi e +\\frac 1 2\\ln|\\Sigma_j|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve for $\\Sigma_i$ (or just by examination through completing the square)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\delta F/\\delta\\Sigma_i &= 0 = \\frac 1 2 L^{(\\vartheta_i \\vartheta_i)} + \\frac 1 2 \\Sigma_i^{-1}\\\\\n",
    "    \\Sigma_i & = {-L^{(\\vartheta_i \\vartheta_i)}}^{-1}\n",
    "    \\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the same procedure can be applied to individual variational density to give\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\ln q(\\vartheta_i) &\\approx V(\\vartheta_i)\\\\\n",
    "    & = \\left\\langle L(\\vartheta_i, \\mu_j) + L^{(\\vartheta_j)}(\\vartheta_i, \\mu_j)(\\vartheta_j - \\mu_j) +\n",
    "        \\frac 1 2 L^{(\\vartheta_j \\vartheta_j)}(\\vartheta_i, \\mu_j)(\\vartheta_j - \\mu_j)^2\\right\\rangle_{q_j}\\\\\n",
    "    V(\\vartheta_i, \\mu_j) &= L(\\vartheta_i, \\mu_j) +\n",
    "        \\frac 1 2 tr(\\Sigma_j L^{(\\vartheta_j \\vartheta_j)})\n",
    "    \\end{align}\n",
    "$$\n",
    "\n",
    "This is useful when optimse for variational mode $\\mu_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### § Optimsation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimise the sufficient statistics for the variational density, $q$, under Laplace approximation, we only need to find their mean and covariance, which are illustrated in the preceding sections\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mu_i &= \\underset{\\vartheta_i}{\\operatorname{argmax}} V(\\vartheta_i)\\\\\n",
    "    \\Sigma_i &= - L(\\mu)^{(\\vartheta_j \\vartheta_j)^{-1}}\n",
    "    \\end{align}\n",
    "$$\n",
    "\n",
    "It is worth noting that the covariance is a function of its variational mode and does not depend on the mean-field approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Optimise for $\\mu_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update scheme should read \n",
    "$$\n",
    "\\begin{align}\n",
    "    V(\\mu_i)^{(\\vartheta_{i:k})} &= L(\\mu)^{(\\vartheta_{i:k})} +\n",
    "        \\frac 1 2 tr(\\Sigma_j L^{\\vartheta_j \\vartheta_j \\vartheta_{i:k}})\\\\\n",
    "    V(\\mu_i)^{(\\vartheta_{i:k}\\vartheta_{i:l})} &=\n",
    "        L(\\mu)^{(\\vartheta_{i:k}\\vartheta_{i:l})} +\n",
    "        \\frac 1 2 tr(\\Sigma_j L^{(\\vartheta_{j}\\vartheta_{j}\\vartheta_{i:k}\\vartheta_{i:l})})\\\\\n",
    "    \\Delta\\mu_i &= (\\exp(tJ) - I)J^{-1}V(\\mu_i)^{(\\vartheta_i)}\\\\\n",
    "    &\\approx -V(\\mu_i)^{(\\vartheta_{i}\\vartheta_{i})^{-1}} V(\\mu_i)^{(\\vartheta_{i})}, \\;\\;\\;\\hbox{if }t \\to \\infty\n",
    "    \\end{align}\n",
    "$$\n",
    "\n",
    "where superscript $(\\vartheta_{i:k})$ denotes partial derivative to the $k$-th element of $\\vartheta_i$. For detailed derivation see _[linearisation](?)_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### § Example 1: Implementational consideration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose one has parameter that factorises into $\\vartheta = \\{\\theta, \\varphi\\}$\n",
    "\n",
    "and let $\\theta=(\\theta_1, \\theta_2)^T$ and $\\varphi = (\\varphi_1, \\varphi_2)^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "    V^{(\\varphi\\varphi)} &= \\left(\n",
    "        \\begin{array}{cc}\n",
    "            V^{(\\varphi_1\\varphi_1)} &\n",
    "            V^{(\\varphi_1\\varphi_2)} \\\\\n",
    "            V^{(\\varphi_2\\varphi_1)} &\n",
    "            V^{(\\varphi_2\\varphi_2)} \n",
    "            \\end{array}\\right)\\\\\n",
    "    & = \\left(\n",
    "        \\begin{array}{cc}\n",
    "            L^{(\\varphi_1\\varphi_1)} &\n",
    "            L^{(\\varphi_1\\varphi_2)} \\\\\n",
    "            L^{(\\varphi_2\\varphi_1)} &\n",
    "            L^{(\\varphi_2\\varphi_2)}\n",
    "            \\end{array}\\right) +\n",
    "        \\frac{1}{2}\\left(\n",
    "        \\begin{array}{cc}\n",
    "            tr\\left[\\Sigma_\\theta L^{(\\theta\\theta\\varphi_1\\varphi_1)}\\right] &\n",
    "            tr\\left[\\Sigma_\\theta L^{(\\theta\\theta\\varphi_1\\varphi_2)}\\right] \\\\\n",
    "            tr\\left[\\Sigma_\\theta L^{(\\theta\\theta\\varphi_2\\varphi_1)}\\right] &\n",
    "            tr\\left[\\Sigma_\\theta L^{(\\theta\\theta\\varphi_2\\varphi_2)}\\right]\n",
    "            \\end{array}\\right)\n",
    "    \\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpack $L^{(\\theta\\theta\\varphi_1\\varphi_1)}$ in the second term\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{cc}\n",
    "    L^{(\\theta_1\\theta_1\\varphi_1\\varphi_1)} &\n",
    "    L^{(\\theta_1\\theta_2\\varphi_1\\varphi_1)} \\\\\n",
    "    L^{(\\theta_2\\theta_1\\varphi_1\\varphi_1)} &\n",
    "    L^{(\\theta_2\\theta_2\\varphi_1\\varphi_1)}\n",
    "    \\end{array}\\right)\n",
    "$$\n",
    "\n",
    "Continue unpacking the second term row-wise and arrange the outcome by columns, one has\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "\\begin{array}{cccc}\n",
    "    L^{(\\theta_1\\theta_1\\varphi_1\\varphi_1)} &\n",
    "    L^{(\\theta_1\\theta_1\\varphi_1\\varphi_2)} &\n",
    "    L^{(\\theta_1\\theta_1\\varphi_2\\varphi_1)} &\n",
    "    L^{(\\theta_1\\theta_1\\varphi_2\\varphi_2)} \\\\\n",
    "    L^{(\\theta_1\\theta_2\\varphi_1\\varphi_1)} &\n",
    "    L^{(\\theta_1\\theta_2\\varphi_1\\varphi_2)} &\n",
    "    L^{(\\theta_1\\theta_2\\varphi_2\\varphi_1)} &\n",
    "    L^{(\\theta_1\\theta_2\\varphi_2\\varphi_2)} \\\\\n",
    "    L^{(\\theta_2\\theta_1\\varphi_1\\varphi_1)} &\n",
    "    L^{(\\theta_2\\theta_1\\varphi_1\\varphi_2)} &\n",
    "    L^{(\\theta_2\\theta_1\\varphi_2\\varphi_1)} &\n",
    "    L^{(\\theta_2\\theta_1\\varphi_2\\varphi_2)} \\\\\n",
    "    L^{(\\theta_2\\theta_2\\varphi_1\\varphi_1)} &\n",
    "    L^{(\\theta_2\\theta_2\\varphi_1\\varphi_2)} &\n",
    "    L^{(\\theta_2\\theta_2\\varphi_2\\varphi_1)} &\n",
    "    L^{(\\theta_2\\theta_2\\varphi_2\\varphi_2)} \\\\\n",
    "    \\end{array}\\right) = \n",
    "    (L'^{(\\theta\\theta\\varphi_1\\varphi_1)},\n",
    "        L'^{(\\theta\\theta\\varphi_1\\varphi_2)},\n",
    "        L'^{(\\theta\\theta\\varphi_2\\varphi_1)},\n",
    "        L'^{(\\theta\\theta\\varphi_2\\varphi_2)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one vectorises the covariance matrix \n",
    "$$\n",
    "\\Sigma_\\theta = \\left(\\begin{array}{cc}\n",
    "    \\Sigma_{\\theta:11} &\n",
    "    \\Sigma_{\\theta:12} \\\\\n",
    "    \\Sigma_{\\theta:21} &\n",
    "    \\Sigma_{\\theta:22}\n",
    "    \\end{array}\\right)\n",
    "$$\n",
    "\n",
    "row-wise\n",
    "\n",
    "$$\n",
    "\\Sigma'_\\theta = (\\Sigma_{\\theta:11}, \\Sigma_{\\theta:12}, \\Sigma_{\\theta:21}, \\Sigma_{\\theta:22})^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can instead write, for instance, $tr\\left[\\Sigma_\\theta L^{(\\theta\\theta\\varphi_1\\varphi_1)}\\right]$ in the following form\n",
    "\n",
    "$$\n",
    "\\left.\\Sigma'^T_\\theta L'^{(\\theta\\theta\\varphi_1\\varphi_1)}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let\n",
    "$$\n",
    "\\begin{align}\n",
    "    U_{11} &= \\Sigma'^T_\\theta L'^{(\\theta\\theta\\varphi_1\\varphi_1)}\\\\\n",
    "    U_{12} &= \\Sigma'^T_\\theta L'^{(\\theta\\theta\\varphi_1\\varphi_2)}\\\\\n",
    "    U_{21} &= \\Sigma'^T_\\theta L'^{(\\theta\\theta\\varphi_2\\varphi_1)}\\\\\n",
    "    U_{22} &= \\Sigma'^T_\\theta L'^{(\\theta\\theta\\varphi_2\\varphi_2)}\\\\\n",
    "    \\end{align}\n",
    "$$\n",
    "\n",
    "And finally\n",
    "\n",
    "$$\n",
    "V^{(\\varphi\\varphi)} = \n",
    "    \\left(\n",
    "        \\begin{array}{cc}\n",
    "            L^{(\\varphi_1\\varphi_1)} &\n",
    "            L^{(\\varphi_1\\varphi_2)} \\\\\n",
    "            L^{(\\varphi_2\\varphi_1)} &\n",
    "            L^{(\\varphi_2\\varphi_2)}\n",
    "            \\end{array}\\right) +\n",
    "        \\frac{1}{2}\\left(\n",
    "        \\begin{array}{cc}\n",
    "            U_{11} & U_{12}\\\\ U_{21} & U_{22}\n",
    "            \\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same procedure can be repeated for $V^{(\\theta\\theta)}, V^{(\\varphi)}$ and $V^{(\\theta)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### § Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theano version:  0.8.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K40c (CNMeM is enabled with initial size: 90.0% of memory, cuDNN Version is too old. Update to v5, was 2000.)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "print(\"Theano version: \", theano.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c0 = [1. / 16, 1. / 8, 1. / 128]\n",
    "u, v = T.vectors(2)\n",
    "Su, Sv = T.matrices(2)\n",
    "\n",
    "L = (-c0[0] * (u - c0[1] * v ** 2) ** 2 - c0[2] * (v ** 2 - 2) ** 2)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective function\n",
    "\n",
    "$\n",
    "L(u, v) = -\\frac{1}{16} (u - \\frac{1}{8}v^2)^2 - \\frac{1}{128} (v^2 - 2)^2\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fSu, fSv = Su.flatten(1), Sv.flatten(1)\n",
    "\n",
    "Lu = T.jacobian(L, u)\n",
    "Lv = T.jacobian(L, v)\n",
    "\n",
    "Luu = T.hessian(L, u).flatten(1)\n",
    "Lvv = T.hessian(L, v).flatten(1)\n",
    "\n",
    "Luuv = T.join(0, [T.jacobian(Luu[i], v) for i in range(1)])\n",
    "Lvvu = T.join(0, [T.jacobian(Lvv[i], u) for i in range(1)])\n",
    "\n",
    "Luuvv = T.join(0, [T.hessian(Luu[i], v).flatten(1) for i in range(1)])\n",
    "Lvvuu = T.join(0, [T.hessian(Lvv[i], u).flatten(1) for i in range(1)])\n",
    "\n",
    "Uu = T.join(0, [T.sum(fSv * Lvvu[:, i]) for i in range(1)])\n",
    "Uv = T.join(0, [T.sum(fSu * Luuv[:, i]) for i in range(1)])\n",
    "\n",
    "Uuu = T.join(0, [T.sum(fSv * Lvvuu[:, i]) for i in range(1)])\n",
    "Uvv = T.join(0, [T.sum(fSu * Luuvv[:, i]) for i in range(1)])\n",
    "\n",
    "Vu = Lu + 0.5 * Uu\n",
    "Vv = Lv + 0.5 * Uv\n",
    "\n",
    "Vuu = (Luu + 0.5 * Uuu).reshape((1, 1))\n",
    "Vvv = (Lvv + 0.5 * Uvv).reshape((1, 1))\n",
    "\n",
    "F = L + 0.5 * (Su.dot(Luu) + Sv.dot(Lvv)) + T.log(T.nlinalg.det(Su)) + T.log(T.nlinalg.det(Sv))\n",
    "\n",
    "\n",
    "du = -(T.nlinalg.pinv(Vuu).dot(Vu))\n",
    "dv = -(T.nlinalg.pinv(Vvv).dot(Vv))\n",
    "\n",
    "# alternatively\n",
    "# du = (T.exp(Vuu) - 1).dot(T.nlinalg.pinv(Vuu).dot(Vu))\n",
    "# dv = (T.exp(Vvv) - 1).dot(T.nlinalg.pinv(Vvv).dot(Vv))\n",
    "\n",
    "Cu = - T.nlinalg.pinv(Luu.reshape((1, 1)))\n",
    "Cv = - T.nlinalg.pinv(Lvv.reshape((1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update = theano.function([u, v, Su, Sv], [du, dv, Cu, Cv], allow_input_downcast=True)\n",
    "elb = theano.function([u, v, Su, Sv], F, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tu, tv = 1., 1.  # delta_u, delta_v\n",
    "\n",
    "u0, v0, Su0, Sv0 = np.array([8.]), np.array([-10.]), np.array([[1.]]), np.array([[1.]])\n",
    "tCu, tCv = Su0, Sv0\n",
    "tol = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged.\n",
      "u:  [ 0.99912137] v:  [-1.6306356] Cu:  [[ 8.]] Cv:  [[ 5.33943176]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f461aa74c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hold(True)\n",
    "\n",
    "step = 0\n",
    "for maxM in range(256):\n",
    "    plt.subplot(211)\n",
    "    plt.plot(v0, u0, 'r+', alpha=1)\n",
    "    for maxN in range(256):\n",
    "        tu, tv, tCu, tCv = update(u0, v0, tCu, tCv)\n",
    "        u0 += tu\n",
    "        v0 += tv\n",
    "        \n",
    "        plt.subplot(211)\n",
    "        plt.plot(v0, u0, 'b.', alpha=.5);\n",
    "        plt.subplot(212)\n",
    "        plt.plot(step, elb(u0, v0, Su0, Sv0), 'r+');\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(0.)\n",
    "        step += 1\n",
    "        if (tu ** 2) < tol and (tv ** 2) < tol: break\n",
    "    if np.sum((Su0 - tCu) ** 2) < tol and np.sum((Sv0 - tCv) ** 2) < tol: break\n",
    "    Su0, Sv0 = tCu, tCv\n",
    "print(\"Converged.\")\n",
    "print(\"u: \", u0, \"v: \", v0, \"Cu: \", Su0, \"Cv: \", Sv0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### § Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stat\n",
    "import numpy as np\n",
    "\n",
    "rad = np.pi / 3\n",
    "\n",
    "di, dj, dk = 2, 2, 2\n",
    "\n",
    "mj, mk = np.array([3., 4.]), np.array([3., 4.])\n",
    "Sj, Sk = np.eye(dj) * 1.5, np.eye(dj) * .1\n",
    "\n",
    "G = np.array([\n",
    "    [ np.cos(rad), np.sin(rad)],\n",
    "    [-np.sin(rad), np.cos(rad)]])\n",
    "\n",
    "N = 300\n",
    "Y = np.zeros((di, N))\n",
    "\n",
    "for n in range(N):\n",
    "    i = stat.multivariate_normal(mean=mj, cov=Sj).rvs()\n",
    "    j = stat.multivariate_normal(mean=mk, cov=Sk).rvs()\n",
    "    Y[:, n] = stat.multivariate_normal(mean=G.dot(i), cov=np.diag(j)).rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(Y.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = T.matrix()\n",
    "pu, pv, u, v = T.vectors(4)\n",
    "Su, Sv = T.matrices(2)\n",
    "Sy = T.nlinalg.diag(v)\n",
    "\n",
    "Py = T.nlinalg.matrix_inverse(Sy)\n",
    "Pu = T.nlinalg.matrix_inverse(Su)\n",
    "Pv = T.nlinalg.matrix_inverse(Sv)\n",
    "\n",
    "ey = y - T.dot(G, u)\n",
    "eu = u - pu\n",
    "ev = v - pv\n",
    "\n",
    "L = - T.sum(ey.dot(Py) * ey) - 0.5 * T.log(T.nlinalg.det(Py)) - 0.5 * N * di * np.log(2 * np.pi)\\\n",
    "    - eu.T.dot(Pu).dot(eu) - 0.5 * T.log(T.nlinalg.det(Pu)) - 0.5 * dj * np.log(2 * np.pi)\\\n",
    "    - ev.T.dot(Pv).dot(ev) - 0.5 * T.log(T.nlinalg.det(Pv)) - 0.5 * dk * np.log(2 * np.pi)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fSu, fSv = Su.flatten(1), Sv.flatten(1)\n",
    "\n",
    "Lu = T.jacobian(L, u)\n",
    "Lv = T.jacobian(L, v)\n",
    "\n",
    "Luu = T.hessian(L, u).flatten(1)\n",
    "Lvv = T.hessian(L, v).flatten(1)\n",
    "\n",
    "Luuv = T.join(0, [T.jacobian(Luu[i], v) for i in range(dj ** 2)])\n",
    "Lvvu = T.join(0, [T.jacobian(Lvv[i], u) for i in range(dk ** 2)])\n",
    "\n",
    "Luuvv = T.join(0, [T.hessian(Luu[i], v).flatten(1) for i in range(dj ** 2)])\n",
    "Lvvuu = T.join(0, [T.hessian(Lvv[i], u).flatten(1) for i in range(dk ** 2)])\n",
    "\n",
    "Uu = T.join(0, [T.sum(fSv * Lvvu[:, i]) for i in range(dj)])\n",
    "Uv = T.join(0, [T.sum(fSu * Luuv[:, i]) for i in range(dk)])\n",
    "\n",
    "Uuu = T.join(0, [T.sum(fSv * Lvvuu[:, i]) for i in range(dj ** 2)])\n",
    "Uvv = T.join(0, [T.sum(fSu * Luuvv[:, i]) for i in range(dk ** 2)])\n",
    "\n",
    "Vu = Lu + 0.5 * Uu\n",
    "Vv = Lv + 0.5 * Uv\n",
    "\n",
    "Vuu = (Luu + 0.5 * Uuu).reshape((dj, dj))\n",
    "Vvv = (Lvv + 0.5 * Uvv).reshape((dk, dk))\n",
    "\n",
    "F = L + 0.5 * (\n",
    "    T.sum(fSu * Luu) + \n",
    "    T.sum(fSv * Lvv)) + T.log(T.nlinalg.det(Su)) + T.log(T.nlinalg.det(Sv))\n",
    "\n",
    "\n",
    "# du = -(T.nlinalg.pinv(Vuu).dot(Vu))\n",
    "# dv = -(T.nlinalg.pinv(Vvv).dot(Vv))\n",
    "\n",
    "# alternatively\n",
    "du = (T.exp(Vuu) - 1).dot(T.nlinalg.pinv(Vuu).dot(Vu))\n",
    "dv = (T.exp(Vvv) - 1).dot(T.nlinalg.pinv(Vvv).dot(Vv))\n",
    "\n",
    "Cu = - T.nlinalg.pinv(Luu.reshape((dj, dj)))\n",
    "Cv = - T.nlinalg.pinv(Lvv.reshape((dk, dk)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update = theano.function([y, u, v, pu, pv, Su, Sv], [du, dv, Cu, Cv], allow_input_downcast=True)\n",
    "elb = theano.function([y, u, v, pu, pv, Su, Sv], F, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elb(Y.T, u0, v0, pu0, pv0, Su0, Sv0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hold(True)\n",
    "\n",
    "u0 = np.array([1., 1.])\n",
    "v0 = np.array([1., 1.])\n",
    "pu0 = np.array([3., 4.])\n",
    "pv0 = np.array([3., 4.])\n",
    "Su0 = np.eye(2)\n",
    "Sv0 = np.eye(2)\n",
    "tol = 0.001\n",
    "\n",
    "step = 0\n",
    "for maxM in range(64):\n",
    "    plt.subplot(311)\n",
    "    plt.plot(u0[0], u0[1], 'r*', alpha=1);\n",
    "    plt.subplot(312)\n",
    "    plt.plot(v0[0], v0[1], 'r*', alpha=1);\n",
    "    for maxN in range(64):\n",
    "        tu, tv, tCu, tCv = update(Y.T, u0, v0, pu0, pv0, Su0, Sv0)\n",
    "        u0 += tu\n",
    "        v0 += tv\n",
    "        \n",
    "        plt.subplot(311)\n",
    "        plt.plot(u0[0], u0[1], 'b.', alpha=.4);\n",
    "        plt.subplot(312)\n",
    "        plt.plot(v0[0], v0[1], 'b.', alpha=.4);\n",
    "        plt.subplot(313)\n",
    "        plt.plot(step, elb(Y.T, u0, v0, pu0, pv0, Su0, Sv0), 'r+');\n",
    "        \n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(0.)\n",
    "        step += 1\n",
    "        \n",
    "        if np.all((tu ** 2) < tol) and np.all((tv ** 2) < tol): break\n",
    "    if np.sum((Su0 - tCu) ** 2) < tol and np.sum((Sv0 - tCv) ** 2) < tol: break\n",
    "    Su0, Sv0 = tCu, tCv\n",
    "print(\"Converged.\")\n",
    "print(\"u: \", u0, \"v: \", v0, \"Cu: \", Su0, \"Cv: \", Sv0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stat\n",
    "import numpy as np\n",
    "\n",
    "rngv = stat.gamma(a=9, scale=3)\n",
    "di, dj, dk = 1, 1, 1\n",
    "N = 500\n",
    "\n",
    "Y = np.zeros((N, 1))\n",
    "\n",
    "for s in range(500):\n",
    "    v = rngv.rvs()\n",
    "    rngu = stat.norm(loc=5, scale=np.sqrt(1 / (2 * v)))\n",
    "    u = rngu.rvs()\n",
    "    Y[s, :] = stat.norm(loc=u, scale=1 / v).rvs()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import functools\n",
    "import theano.tensor as T\n",
    "\n",
    "y = T.matrix()\n",
    "u, v, pu, pv = T.vectors(4)\n",
    "\n",
    "L = T.sum((y - u).dot(T.nlinalg.matrix_inverse(v)) * (y - u)) +\\\n",
    "    ((u - pu[0]).dot(T.nlinalg.matrix_inverse(T.diag(pu[1] * v)))).dot(u - pu[0]) -\\\n",
    "    T.gammaln(pv[0]) * pv[1] ** pv[0] + (pv[0] - 1) * T.log(v) - v / pv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vilaps(L, y, b, bdims, hp=[]):\n",
    "    # inputs:\n",
    "    #  L - log generative density (symbolic, scalar)\n",
    "    #  Y - observation (symbolic, matrix)\n",
    "    #  b – parameters (list of symbols, vector)\n",
    "    #  bdims - dimension of individual parameters (list of int)\n",
    "    #  hb - hyperpriors (list of symbols, vector)\n",
    "    # returns:\n",
    "    #  \n",
    "    assert len(b) == len(bdims)\n",
    "    \n",
    "    mfp = len(bdims)\n",
    "    \n",
    "    Li  = [T.jacobian(L, b[i]) for i in range(mfp)]\n",
    "    Lii = [T.hessian(L, b[i]).flatten(1) for i in range(mfp)]\n",
    "       \n",
    "    Liij  = [[T.join(0, [T.jacobian(Lii[i][k], b[j]) for k in range(bdims[i] ** 2)])\n",
    "              for j in range(mfp)\n",
    "              if j != i]\n",
    "             for i in range(mfp)]\n",
    "    Liijj = [[T.join(0, [T.hessian(Lii[i][k], b[j]).flatten(1) for k in range(bdims[i] ** 2)])\n",
    "              for j in range(mfp)\n",
    "              if j != i]\n",
    "             for i in range(mfp)]\n",
    "    \n",
    "    Ci  = [- T.nlinalg.pinv(Lii[i].reshape((bdims[i], bdims[i]))) for i in range(mfp)]\n",
    "    fCi = [Ci[i].flatten(1) for i in range(mfp)]\n",
    "\n",
    "    Ui = [[T.join(0, [T.sum(fCi[j] * Liij[j][i][:, k]) for k in range(bdims[i])])\n",
    "           for j in range(mfp)\n",
    "           if j != i]  # FIXME indexing\n",
    "          for i in range(mfp)]\n",
    "    Uii = [[T.join(0, [T.sum(fCi[j] * Liijj[j][i][:, k]) for k in range(bdims[i] ** 2)])\n",
    "           for j in range(mfp)\n",
    "           if j != i]  # FIXME indexing\n",
    "          for i in range(mfp)]\n",
    "    \n",
    "    Vi  = [Li[i] + 0.5 * functools.reduce(lambda x, y: x + y, Ui[i]) for i in range(mfp)]\n",
    "    Vii = [(Lii[i] + 0.5 * functools.reduce(lambda x, y: x + y, Uii[i])).reshape((bdims[i], bdims[i]))\n",
    "           for i in range(mfp)]\n",
    "    \n",
    "    bGN = [-T.nlinalg.pinv(Vii[i]).dot(Vi[i]) for i in range(mfp)]\n",
    "    # bLM = [(T.exp(Vii[i]) - 1).dot(T.nlinalg.pinv(Vii[i])).dot(Vi[i]) for i in range(mfp)]\n",
    "\n",
    "\n",
    "    F = L\n",
    "    for i in range(mfp):\n",
    "        F += 0.5 * T.sum(fCi[i] * Lii[i] + T.log(T.nlinalg.det(Ci[i])))\n",
    "    \n",
    "    step = theano.function([Y] + b + hp, [bGN, Ci, F], allow_input_downcast=True)\n",
    "    \n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-7f6a6a4c77bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mc0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvilaps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-f17ff09bbcc5>\u001b[0m in \u001b[0;36mvilaps\u001b[1;34m(L, y, b, bdims, hp)\u001b[0m\n\u001b[0;32m     30\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m            if j != i]\n\u001b[1;32m---> 32\u001b[1;33m           for i in range(mfp)]\n\u001b[0m\u001b[0;32m     33\u001b[0m     Uii = [[T.join(0, [T.sum(fCi[j] * Liijj[j][i][:, k]) for k in range(bdims[i] ** 2)])\n\u001b[0;32m     34\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-f17ff09bbcc5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     30\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m            if j != i]\n\u001b[1;32m---> 32\u001b[1;33m           for i in range(mfp)]\n\u001b[0m\u001b[0;32m     33\u001b[0m     Uii = [[T.join(0, [T.sum(fCi[j] * Liijj[j][i][:, k]) for k in range(bdims[i] ** 2)])\n\u001b[0;32m     34\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-f17ff09bbcc5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     29\u001b[0m     Ui = [[T.join(0, [T.sum(fCi[j] * Liij[j][i][:, k]) for k in range(bdims[i])])\n\u001b[0;32m     30\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m            if j != i]\n\u001b[0m\u001b[0;32m     32\u001b[0m           for i in range(mfp)]\n\u001b[0;32m     33\u001b[0m     Uii = [[T.join(0, [T.sum(fCi[j] * Liijj[j][i][:, k]) for k in range(bdims[i] ** 2)])\n",
      "\u001b[1;32m<ipython-input-12-f17ff09bbcc5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mfCi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     Ui = [[T.join(0, [T.sum(fCi[j] * Liij[j][i][:, k]) for k in range(bdims[i])])\n\u001b[0m\u001b[0;32m     30\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m            if j != i]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "c0 = [1. / 16, 1. / 8, 1. / 128]\n",
    "u, v = T.vectors(2)\n",
    "\n",
    "L = (-c0[0] * (u - c0[1] * v ** 2) ** 2 - c0[2] * (v ** 2 - 2) ** 2)[0]\n",
    "\n",
    "step = vilaps(L, 0, [u, v], [1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace approxmation & free-action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1 Multivariate normal distribution\n",
    "<a id=\"A.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say $\\pmb x \\sim N(\\pmb\\mu, \\pmb\\Lambda^{-1})$\n",
    "\n",
    "Then,\n",
    "\n",
    "$\n",
    "\\ln p(\\pmb x) = -\\frac D 2\\ln 2\\pi - \\frac 1 2 \\ln|\\pmb\\Lambda^{-1}| - \\frac 1 2 (\\pmb x-\\pmb\\mu)^T\\pmb\\Lambda(\\pmb x-\\pmb\\mu)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "H(\\pmb x) = \\langle -\\ln \\pmb x\\rangle = \\frac D 2\\ln 2\\pi e + \\frac 1 2 \\ln |\\pmb\\Lambda^{-1}|\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "D = \\dim(\\pmb x)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2 Matrix derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\frac{d}{d\\Sigma}\\ln\\det(\\Sigma) = \\frac{d}{\\det(\\Sigma)}\\ln\\det(\\Sigma)\\frac{d}{d\\Sigma}\\det(\\Sigma)\n",
    "$    (chain rule) $= \\det'(\\Sigma)/\\det(\\Sigma) = \\Sigma^{-1}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
